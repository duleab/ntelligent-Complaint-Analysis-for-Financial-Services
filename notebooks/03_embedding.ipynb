{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Text Preprocessing for Consumer Complaints\n",
       "\n",
       "This notebook implements text cleaning and preprocessing steps for the consumer complaints data before vector embedding and analysis."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Setup and Imports"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import pandas as pd\n",
       "import numpy as np\n",
       "import re\n",
       "import string\n",
       "from tqdm.notebook import tqdm\n",
       "\n",
       "# Set display options\n",
       "pd.set_option('display.max_columns', None)\n",
       "pd.set_option('display.max_colwidth', 200)\n",
       "\n",
       "# Suppress warnings\n",
       "import warnings\n",
       "warnings.filterwarnings('ignore')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Load the Raw Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load the raw complaints data\n",
       "data_path = '../data/raw/consumer_complaints.csv'\n",
       "complaints_df = pd.read_csv(data_path)\n",
       "\n",
       "# Display basic information\n",
       "print(f'Dataset shape: {complaints_df.shape}')\n",
       "print('\\nColumns:', list(complaints_df.columns))\n",
       "complaints_df.head()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Text Cleaning Functions"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def remove_boilerplate(text):\n",
       "    \"\"\"Remove common boilerplate and redacted information.\"\"\"\n",
       "    if not isinstance(text, str):\n",
       "        return \"\"\n",
       "    \n",
       "    # Common patterns to remove\n",
       "    patterns = [\n",
       "        r'XX+',  # XXXX, XX/XX/XXXX, etc.\n",
       "        r'\\d{2}/\\d{2}/\\d{4}',  # Dates in XX/XX/XXXX format\n",
       "        r'\\b\\d{10,}\\b',  # Long numbers (likely account/SSN)\n",
       "        r'\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b',  # Email addresses\n",
       "        r'\\bhttps?://\\S+\\b',  # URLs\n",
       "        r'\\b\\d{3}-\\d{2}-\\d{4}\\b',  # SSN pattern\n",
       "        r'\\b\\d{4}[-\\.]?\\d{4}[-\\.]?\\d{4}[-\\.]?\\d{4}\\b',  # Credit card numbers\n",
       "        r'\\[.*?\\]',  # Anything in square brackets\n",
       "        r'\\(.*?\\)',  # Anything in parentheses\n",
       "        r'\\b(?:redacted|omitted|removed|confidential|private|personal information|PII|PHI)\\b',\n",
       "        r'\\b(?:name|address|phone|ssn|account|number|social security|credit card|debit card|bank account)\\s*:.*?(?=\\s+\\w+:|$)'\n",
       "    ]\n",
       "    \n",
       "    # Combine patterns and apply\n",
       "    pattern = '|'.join(patterns)\n",
       "    text = re.sub(pattern, ' ', text, flags=re.IGNORECASE)\n",
       "    \n",
       "    return text.strip()\n",
       "\n",
       "def remove_special_characters(text):\n",
       "    \"\"\"Remove special characters while preserving basic punctuation and alphanumeric characters.\"\"\"\n",
       "    if not isinstance(text, str):\n",
       "        return \"\"\n",
       "    \n",
       "    # Keep alphanumeric, basic punctuation, and whitespace\n",
       "    text = re.sub(r'[^\\w\\s.,!?-]', ' ', text)\n",
       "    \n",
       "    # Remove any remaining special characters\n",
       "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
       "    \n",
       "    return text.strip()\n",
       "\n",
       "def remove_extra_whitespace(text):\n",
       "    \"\"\"Normalize whitespace in text.\"\"\"\n",
       "    if not isinstance(text, str):\n",
       "        return \"\"\n",
       "    \n",
       "    # Replace multiple whitespace with single space\n",
       "    text = ' '.join(text.split())\n",
       "    \n",
       "    return text.strip()\n",
       "\n",
       "def clean_text(text):\n",
       "    \"\"\"Main function to clean text using all cleaning functions.\"\"\"\n",
       "    if not isinstance(text, str):\n",
       "        return \"\"\n",
       "    \n",
       "    # Apply cleaning steps in order\n",
       "    text = text.strip()\n",
       "    text = remove_boilerplate(text)\n",
       "    text = remove_special_characters(text)\n",
       "    text = remove_extra_whitespace(text)\n",
       "    \n",
       "    return text"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Apply Text Cleaning"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Select the text column to clean (adjust based on your data)\n",
       "text_column = 'Consumer complaint narrative'  # Update this based on your column name\n",
       "\n",
       "# Create a copy of the dataframe to avoid modifying the original\n",
       "cleaned_df = complaints_df.copy()\n",
       "\n",
       "# Apply cleaning to the text column\n",
       "print(\"Cleaning text data...\")\n",
       "tqdm.pandas()\n",
       "cleaned_df['cleaned_narrative'] = cleaned_df[text_column].progress_apply(clean_text)\n",
       "\n",
       "# Remove rows with empty cleaned text\n",
       "initial_count = len(cleaned_df)\n",
       "cleaned_df = cleaned_df[cleaned_df['cleaned_narrative'].str.len() > 0].copy()\n",
       "final_count = len(cleaned_df)\n",
       "\n",
       "print(f\"\\nRemoved {initial_count - final_count} empty rows after cleaning.\")\n",
       "print(f\"Final dataset size: {final_count} rows\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Save Cleaned Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Create output directory if it doesn't exist\n",
       "import os\n",
       "os.makedirs('../data/processed', exist_ok=True)\n",
       "\n",
       "# Save cleaned data\n",
       "output_path = '../data/processed/cleaned_complaints.csv'\n",
       "cleaned_df.to_csv(output_path, index=False)\n",
       "\n",
       "print(f\"Cleaned data saved to: {output_path}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Sample Before and After Cleaning"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Display sample of original and cleaned text\n",
       "sample = cleaned_df.sample(5, random_state=42)\n",
       "\n",
       "for idx, row in sample.iterrows():\n",
       "    print(\"=\"*100)\n",
       "    print(\"\\nORIGINAL TEXT:\")\n",
       "    print(row[text_column])\n",
       "    print(\"\\nCLEANED TEXT:\")\n",
       "    print(row['cleaned_narrative'])\n",
       "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }