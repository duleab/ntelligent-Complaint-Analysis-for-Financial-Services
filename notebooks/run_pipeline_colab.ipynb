# Run this cell first to set up the environment
!pip install -q transformers sentence-transformers langchain langchain-community faiss-cpu pandas numpy

import os
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import time

# Download the data
!wget -q https://files.consumerfinance.gov/ccdb/complaints.csv.zip
!unzip -q complaints.csv.zip

# Load the data in chunks
chunk_size = 100000
df = pd.DataFrame()
for chunk in pd.read_csv('complaints.csv', chunksize=chunk_size):
    # Filter for records with narratives
    filtered_chunk = chunk.dropna(subset=['Consumer complaint narrative'])
    df = pd.concat([df, filtered_chunk])
    if len(df) > 1000000:  # Process first 1M records for demo
        break

# Initialize embeddings model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')

# Create FAISS index
embedding_dim = 384  # Dimension of the embeddings
dimension = embedding_dim
nlist = 100  # Number of clusters
quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

# Process chunks of data
batch_size = 1000
num_batches = len(df) // batch_size

start_time = time.time()

for i in range(num_batches):
    if i % 10 == 0:  # Print progress every 10 batches
        elapsed_time = time.time() - start_time
        print(f'Processing batch {i}/{num_batches} - Time elapsed: {elapsed_time:.2f} seconds')
    
    # Get batch of data
    start_idx = i * batch_size
    end_idx = min((i + 1) * batch_size, len(df))
    batch = df.iloc[start_idx:end_idx]
    
    # Get embeddings
    texts = batch['Consumer complaint narrative'].tolist()
    embeddings = model.encode(texts, batch_size=32, show_progress_bar=False)
    
    # Add to FAISS index
    if not index.is_trained:
        index.train(embeddings)
    index.add(embeddings)

# Save the index
faiss.write_index(index, 'complaints_vector_store.index')

# Test the vector store
query = "What are common issues with credit cards?"
query_embedding = model.encode([query])
D, I = index.search(query_embedding, k=5)

# Print results
print("\nSearch Results:")
for i in range(5):
    idx = I[0][i]
    print(f"\nResult {i+1}:")
    print(f"Score: {D[0][i]}")
    print(f"Text: {df.iloc[idx]['Consumer complaint narrative'][:500]}...")
    print(f"Product: {df.iloc[idx]['Product']}")
    print(f"Issue: {df.iloc[idx]['Issue']}")
